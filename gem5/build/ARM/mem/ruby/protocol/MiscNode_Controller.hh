/**
 * DO NOT EDIT THIS FILE!
 * File automatically generated by
 *   /home/a599m019/gem5-fullsys-enviroment/gem5/src/mem/slicc/symbols/StateMachine.py:532
 */

// Created by slicc definition of Module "CHI Misc Node for handling and distrbuting DVM operations"

#ifndef __MiscNode_CONTROLLER_HH__
#define __MiscNode_CONTROLLER_HH__

#include <iostream>
#include <sstream>
#include <string>

#include "mem/ruby/common/Consumer.hh"
#include "mem/ruby/protocol/TransitionResult.hh"
#include "mem/ruby/protocol/Types.hh"
#include "mem/ruby/slicc_interface/AbstractController.hh"
#include "params/MiscNode_Controller.hh"

#include "mem/ruby/protocol/MN_TBETable.hh"
#include "mem/ruby/protocol/TBEStorage.hh"
#include "mem/ruby/protocol/MN_TBEStorage.hh"
namespace gem5
{

namespace ruby
{

extern std::stringstream MiscNode_transitionComment;

class MiscNode_Controller : public AbstractController
{
  public:
    typedef MiscNode_ControllerParams Params;
    MiscNode_Controller(const Params &p);
    static int getNumControllers();
    void init();

    MessageBuffer *getMandatoryQueue() const;
    MessageBuffer *getMemReqQueue() const;
    MessageBuffer *getMemRespQueue() const;
    void initNetQueues();

    void print(std::ostream& out) const;
    void wakeup();
    void resetStats();
    void regStats();
    void collateStats();

    void recordCacheTrace(int cntrl, CacheRecorder* tr);
    Sequencer* getCPUSequencer() const;
    DMASequencer* getDMASequencer() const;
    GPUCoalescer* getGPUCoalescer() const;

    bool functionalReadBuffers(PacketPtr&);
    bool functionalReadBuffers(PacketPtr&, WriteMask&);
    int functionalWriteBuffers(PacketPtr&);

    void countTransition(MiscNode_State state, MiscNode_Event event);
    void possibleTransition(MiscNode_State state, MiscNode_Event event);
    uint64_t getEventCount(MiscNode_Event event);
    bool isPossible(MiscNode_State state, MiscNode_Event event);
    uint64_t getTransitionCount(MiscNode_State state, MiscNode_Event event);

private:
    Cycles m_snp_latency;
    Cycles m_snp_inv_latency;
    Cycles m_allocation_latency;
    Cycles m_request_latency;
    Cycles m_response_latency;
    Cycles m_sched_response_latency;
    Cycles m_snoop_latency;
    Cycles m_data_latency;
    Cycles m_stall_recycle_lat;
    int m_number_of_DVM_TBEs;
    int m_number_of_non_sync_TBEs;
    bool m_dealloc_wait_for_tag;
    int m_data_channel_size;
    bool m_early_nonsync_comp;
    Cycles m_comp_wu_latency;
    Cycles m_retry_ack_latency;
    Cycles m_crd_grant_latency;
    Cycles m_retry_req_latency;
    bool m_throttle_req_on_retry;
    MessageBuffer* m_reqOut_ptr;
    MessageBuffer* m_snpOut_ptr;
    MessageBuffer* m_rspOut_ptr;
    MessageBuffer* m_datOut_ptr;
    MessageBuffer* m_reqIn_ptr;
    MessageBuffer* m_snpIn_ptr;
    MessageBuffer* m_rspIn_ptr;
    MessageBuffer* m_datIn_ptr;
    MessageBuffer* m_mandatoryQueue_ptr;
    MessageBuffer* m_triggerQueue_ptr;
    MessageBuffer* m_retryTriggerQueue_ptr;
    MessageBuffer* m_schedRspTriggerQueue_ptr;
    MessageBuffer* m_reqRdy_ptr;
    MessageBuffer* m_snpRdy_ptr;
    TransitionResult doTransition(MiscNode_Event event,
                                  MiscNode_TBE* m_tbe_ptr,
                                  Addr addr);

    TransitionResult doTransitionWorker(MiscNode_Event event,
                                        MiscNode_State state,
                                        MiscNode_State& next_state,
                                        MiscNode_TBE*& m_tbe_ptr,
                                        Addr addr);

    MiscNode_Event m_curTransitionEvent;
    MiscNode_State m_curTransitionNextState;

    MiscNode_Event curTransitionEvent() { return m_curTransitionEvent; }
    MiscNode_State curTransitionNextState() { return m_curTransitionNextState; }

    int m_counters[MiscNode_State_NUM][MiscNode_Event_NUM];
    int m_event_counters[MiscNode_Event_NUM];
    bool m_possible[MiscNode_State_NUM][MiscNode_Event_NUM];

    static std::vector<statistics::Vector *> eventVec;
    static std::vector<std::vector<statistics::Vector *> > transVec;
    static int m_num_controllers;

    // Internal functions
    void notifyPfHit(const RequestPtr& param_req, const bool& param_is_read, const DataBlock& param_blk);
    void notifyPfMiss(const RequestPtr& param_req, const bool& param_is_read, const DataBlock& param_blk);
    void notifyPfFill(const RequestPtr& param_req, const DataBlock& param_blk, const bool& param_from_pf);
    void notifyPfEvict(const Addr& param_blkAddr, const bool& param_hwPrefetched);
    void notifyPfComplete(const Addr& param_addr);
    int tbePartition(const bool& param_is_non_sync);
    MiscNode_State getState(MiscNode_TBE* param_tbe, const Addr& param_txnId);
    void setState(MiscNode_TBE* param_tbe, const Addr& param_txnId, const MiscNode_State& param_state);
    MiscNode_TBE* nullTBE();
    MiscNode_TBE* getCurrentActiveTBE(const Addr& param_txnId);
    AccessPermission getAccessPermission(const Addr& param_txnId);
    void setAccessPermission(const Addr& param_txnId, const MiscNode_State& param_state);
    void functionalRead(const Addr& param_txnId, Packet* param_pkt, WriteMask& param_mask);
    int functionalWrite(const Addr& param_txnId, Packet* param_pkt);
    Cycles mandatoryQueueLatency(const RubyRequestType& param_type);
    Cycles tagLatency(const bool& param_from_sequencer);
    Cycles dataLatency();
    bool inCache(const Addr& param_txnId);
    bool hasBeenPrefetched(const Addr& param_txnId);
    bool inMissQueue(const Addr& param_txnId);
    void notifyCoalesced(const Addr& param_txnId, const RubyRequestType& param_type, const RequestPtr& param_req, const DataBlock& param_data_blk, const bool& param_was_miss);
    MiscNode_Event reqToEvent(const CHIRequestType& param_type);
    MiscNode_Event respToEvent(const CHIResponseType& param_type);
    MiscNode_Event dataToEvent(const CHIDataType& param_type);
    void clearExpectedReqResp(MiscNode_TBE* param_tbe);
    void clearExpectedSnpResp(MiscNode_TBE* param_tbe);
    void initializeTBE(MiscNode_TBE* param_tbe, const Addr& param_txnId, const int& param_storSlot);
    MiscNode_TBE* allocateDvmRequestTBE(const Addr& param_txnId, const CHIRequestMsg& param_in_msg);
    void deallocateDvmTBE(MiscNode_TBE* param_tbe);
    void clearPendingAction(MiscNode_TBE* param_tbe);
    void processRetryQueue();
    void printResources();
    void printTBEState(MiscNode_TBE* param_tbe);
    void prepareRequest(MiscNode_TBE* param_tbe, const CHIRequestType& param_type, CHIRequestMsg& param_out_msg);
    bool rspInPort_rsc_stall_handler();
    bool datInPort_rsc_stall_handler();
    bool snpInPort_rsc_stall_handler();
    bool reqInPort_rsc_stall_handler();
    bool triggerInPort_rsc_stall_handler();
    void wakeupPendingTgrs(MiscNode_TBE* param_tbe);
    bool reqRdyPort_rsc_stall_handler();
    void wakeupPendingReqs(MiscNode_TBE* param_tbe);
    void processNextState(MiscNode_TBE* param_tbe);
    void updatePendingOps();

    // Set and Reset for tbe variable
    void set_tbe(MiscNode_TBE*& m_tbe_ptr, MiscNode_TBE* m_new_tbe);
    void unset_tbe(MiscNode_TBE*& m_tbe_ptr);

    // Actions
    /** \brief  */
    void AllocateTBE_Request(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void AllocateTBE_Request_WithCredit(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void Initiate_Request_DVM(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void Pop_ReqRdyQueue(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void Receive_ReqDataResp(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void Pop_DataInQueue(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void Receive_SnpResp(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void Pop_RespInQueue(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void ProcessNextState(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void ProcessNextState_ClearPending(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void Send_Comp(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void Send_Comp_NonSync(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void Pop_TriggerQueue(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void Pop_RetryTriggerQueue(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void Finalize_DeallocateRequest(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void Send_DvmNonSyncDBIDResp(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void Send_DvmSyncDBIDResp(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void Send_RetryAck(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void Send_PCrdGrant(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void Send_DvmSnoop_P1(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void Send_DvmSnoop_P2(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void Enqueue_UpdatePendingOps(MiscNode_TBE*& m_tbe_ptr, Addr addr);
    /** \brief  */
    void Profile_OutgoingEnd_DVM(MiscNode_TBE*& m_tbe_ptr, Addr addr);

    // Objects
    int* m_blockSize_ptr;
    MN_TBETable* m_dvmTBEs_ptr;
    TBEStorage* m_nonSyncTBEs_ptr;
    TBEStorage* m_genericTBEs_ptr;
    MN_TBEStorage<MiscNode_RetryQueueEntry>* m_storDvmTBEs_ptr;
    Addr* m_currentDistributor_ptr;
    bool* m_hasCurrentDistributor_ptr;
    bool* m_needsToCheckPendingOps_ptr;
};

} // namespace ruby
} // namespace gem5

#endif // __MiscNode_CONTROLLER_H__
